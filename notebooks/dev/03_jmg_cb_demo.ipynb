{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo of the CrunchBase data\n",
    "\n",
    "This highlights key aspects of the cb+ dataset, which enriches CB with information about their sectors based on a clustering & supervised machine learning analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../notebook_preamble.ipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_diagonal(corr):\n",
    "    '''\n",
    "    Utility to drop diagonal in a correlation matrix so we can visualise it as a heatmap\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    sector_corr_array = np.array(corr)\n",
    "\n",
    "    np.fill_diagonal(sector_corr_array,0)\n",
    "\n",
    "    out = pd.DataFrame(sector_corr_array,index=corr.index,columns=corr.columns)\n",
    "\n",
    "    return(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_meta = pd.read_csv('../../data/processed/17_9_2019_predicted_metadata.csv',compression='zip')\n",
    "\n",
    "cb_labels = pd.read_csv('../../data/processed/17_9_2019_predicted_sectors.csv',compression='zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Showcase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `cb_meta` \n",
    "\n",
    "`cb_meta` contains metadata about CrunchBase companies for which we have predicted labels.\n",
    "\n",
    "Some observations:\n",
    "\n",
    "* This only includes organisations in the company role\n",
    "* This only includes organisations with long descriptions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_meta.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `cb_labels` \n",
    "\n",
    "`cb_labels` contains predicted probabilities for all the sectors we are studying (61 sectors, based on a clustering analysis carried out in `1_jmg_load`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove that unnamed column\n",
    "cb_labels = cb_labels.iloc[:,1:]\n",
    "\n",
    "sectors = cb_labels.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine them into `cb_combi`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_combi = pd.concat([cb_meta,cb_labels],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we need to create a year variable\n",
    "cb_combi['year']= [int(x.split('-')[0]) if pd.isnull(x)==False else np.nan for x in cb_combi['founded_on']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Number of companies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trends\n",
    "cb_combi['year'].value_counts().loc[np.arange(min(cb_combi['year']),max(cb_combi['year']))].fillna(0).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CrunchBase includes data about very old companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_meta.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Funding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_combi.groupby('year')['funding_total_usd'].sum().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this is capturing amount of funding by *year when a company was founded*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Geographies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_countries = cb_combi['country'].value_counts(normalize=True)[:20].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_combi['country'].value_counts(normalize=True)[:20].plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this country variable is based on Nesta's own geocoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = (cb_combi.groupby('country')['funding_total_usd'].sum().sort_values(ascending=False)/1e9)[:20].plot.bar()\n",
    "\n",
    "ax.set_ylabel('Billion $')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = pd.crosstab(cb_combi['year'],cb_combi['country'],normalize=0).loc[np.arange(2000,2019),top_countries[:10]].rolling(3).mean().dropna().plot.bar(stacked=True,width=0.9)\n",
    "ax.legend(bbox_to_anchor=(1,1))\n",
    "\n",
    "ax.set_xlabel('% of all activity accounted by country')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sectors\n",
    "\n",
    "We label each company with its top sector. We also create a variable that only considers a company in a sector if its weight is >0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Focus on dominant sector\n",
    "\n",
    "cb_combi['dominant_sector']= cb_combi[sectors].max(axis=1)>0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_combi['sector_top'] = cb_combi[sectors].idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_combi['sector_dom'] = [r['sector_top'] if r['dominant_sector']==True else 'mixed' for cid,r in cb_combi.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_combi['sector_dom'].value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although it is somewhat surprising to find health as the largest vertical, we assume that this is at least partly caused by the aggregate nature of the category by comparison to eg software"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random check of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_example(df,number,length):\n",
    "    '''\n",
    "    Gets random examples in a field\n",
    "    \n",
    "    Args:\n",
    "        Df is the dataframe we want to use\n",
    "        number is the number of examples we want\n",
    "        length is the length of the examples\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    choose = random.sample(list(df.index),number)\n",
    "    \n",
    "    for x in df.loc[choose]['long_description']:\n",
    "        \n",
    "        print(x[:length])\n",
    "        print('\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in sectors:\n",
    "    \n",
    "    print(x)\n",
    "    print('===')\n",
    "    \n",
    "    in_sector = cb_combi.loc[cb_combi['sector_dom']==x]\n",
    "    \n",
    "    get_example(in_sector,3,700)\n",
    "    \n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sector_trends = pd.crosstab(cb_combi['sector_dom'],cb_combi['year'],normalize=0).loc[:,np.arange(2005,2019)].sort_values(2018,ascending=False)\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(7,15))\n",
    "\n",
    "sns.heatmap(sector_trends,cmap='bwr',ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Funding trends**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funding_sector_trends= cb_combi.groupby(\n",
    "    ['year','sector_dom'])['funding_total_usd'].sum().reset_index(drop=False).pivot_table(index='sector_dom',columns='year',values='funding_total_usd').fillna(0)\n",
    "\n",
    "funding_sector_trend_norm = funding_sector_trends.apply(lambda x: x/x.sum(),axis=1)\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(7,18))\n",
    "\n",
    "sns.heatmap(funding_sector_trend_norm.sort_values(2018,ascending=False).loc[:,np.arange(2008,2019)],ax=ax,cmap='bwr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sector clusters\n",
    "\n",
    "We want to create a cheap visualisation of a network. We will use sector similarities and the sns clustermap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sims = drop_diagonal(pd.DataFrame(1-pairwise_distances(np.array(cb_combi[sectors].applymap(lambda x: 1 if x>0.5 else 0)).T,metric='jaccard'),index=sectors,columns=sectors))\n",
    "\n",
    "\n",
    "sims = drop_diagonal(pd.DataFrame(1-pairwise_distances(cb_combi[sectors].T,metric='cosine'),index=sectors,columns=sectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(sims,cmap='bwr',figsize=(16,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_getters.labs.core import upload_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_combi.to_csv(f'../../data/processed/{today_str}_cb_sector_labelled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
