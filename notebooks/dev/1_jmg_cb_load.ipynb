{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CrunchBase\n",
    "\n",
    "This loads the CrunchBase data from Nesta's DAPS system\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../notebook_preamble.ipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from data_getters.core import get_engine\n",
    "from data_getters.inspector import get_schemas\n",
    "from random import sample\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "today_str = str(datetime.date.today())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We create this type to deal with some Nones later\n",
    "NoneType = type(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connection to the database\n",
    "\n",
    "my_config_here =\"../../mysqldb_team.config\"\n",
    "\n",
    "con = get_engine(my_config_here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read organisations\n",
    "comps_chunks = pd.read_sql_table('crunchbase_organizations', con, chunksize=1000)\n",
    "\n",
    "#Read categories\n",
    "cats_chunks = pd.read_sql_table('crunchbase_organizations_categories', con, chunksize=1000)\n",
    "\n",
    "#Concatenate the chunks into dfs\n",
    "comps, cats = [pd.concat(x).reset_index(drop=True) for x in [comps_chunks,cats_chunks]]\n",
    "#descr_short, descr_long = [comps[v].apply(lambda x: x.lower() if type(x)==str else np.nan) for v in ['short_description','long_description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(comps))\n",
    "\n",
    "print(len(cats))\n",
    "\n",
    "print(len(set(cats['organization_id'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are around 50,000 organisations without categories\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine comps and cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge organisations and categories\n",
    "\n",
    "#We reset the index because you can't merge series\n",
    "cats_grouped = cats.groupby('organization_id')['category_name'].apply(lambda x: list(x)).reset_index(drop=False)\n",
    "\n",
    "#This gives us a dataframe with a new field with the list of categories for the organisation\n",
    "comps_cats = pd.merge(comps,cats_grouped,left_on='id',right_on='organization_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comps_cats.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is as expected given the length of dfs above (there seems to be a small number of organisations in the `cat` df not included in the `comps` df but we can worry about that a bit later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge comps and locations\n",
    "\n",
    "Merges companies and locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = pd.read_sql('geographic_data',con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comps_geo = pd.merge(comps_cats,locations,left_on='location_id',right_on='id',suffixes=['','_locs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop repeated columns\n",
    "comps_geo.drop([x for x in comps_geo.columns if '_locs' in x],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comps_geo.to_csv(f'../../data/external/{today_str}_cb_companies.csv',compression='zip',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
